{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import pickle\n",
    "import flair\n",
    "import sagemaker\n",
    "import torch\n",
    "import tarfile\n",
    "\n",
    "role = get_execution_role()\n",
    "print(torch.cuda.is_available()) # we have gpus available (ml.p2.xlarge)\n",
    "print(torch.cuda.device_count()) # we have 1 GPU on this machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manage interactions with the Amazon SageMaker APIs and any other AWS services needed.\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# uses a default bucket created by sagemaker\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# Region of our account\n",
    "region = \"us-east-1\"\n",
    "\n",
    "# We will use these values when using batch transform\n",
    "prefix_input = 'flair-input'\n",
    "prefix_output = 'flair-ouput'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets download the pre-trained sequence model\n",
    "\n",
    "- We also need to save this model and then tar.gz it in order to make it compatible with sagemaker for inference\n",
    "    - This applies for both realtime endpoints and for batch transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import SequenceTagger\n",
    "\n",
    "# Will download the model with pre-trained weights\n",
    "model = SequenceTagger.load('ner')\n",
    "\n",
    "# Saving the model to disk\n",
    "torch.save(model, \"flair_model.pth\")\n",
    "\n",
    "# Utility function to wrap model inside a tar.gz\n",
    "def tar_gz_model(model_filename):\n",
    "    with tarfile.open('model.tar.gz', 'w:gz') as f:\n",
    "        f.add(f'./{model_filename}')\n",
    "        \n",
    "\n",
    "#creating tar.gz file\n",
    "tar_gz_model('flair_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now store this model artifact on S3 where sagemaker can find it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp model.tar.gz s3://pytorch-flair-test/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now do some local mode inferencing\n",
    "\n",
    "- Local mode is a great way to iteratively experiment with your model as well as any associated scripts for inferencing.\n",
    "- Local mode allows you to spin up a container on your notebook instance, that is identical to a dedicated endpoint, from an environment perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to create a PyTorchModel from our model.tar.gz\n",
    "from sagemaker.pytorch.model import PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__authors__ = [\u001b[33m'\u001b[39;49;00m\u001b[33mIbrahim Gabr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mVadim Dabravolski\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mflair.data\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Sentence\r\n",
      "\r\n",
      "JSON_CONTENT_TYPE = \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "CSV_CONTENT_TYPE = \u001b[33m'\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "PICKLE_CONTENT_TYPE = \u001b[33m'\u001b[39;49;00m\u001b[33mpickle\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "\u001b[37m# Ensure logging to /logs/mms_logs.log in the container.\u001b[39;49;00m\r\n",
      "\u001b[37m# Logging everything from INFO level and above\u001b[39;49;00m\r\n",
      "\u001b[37m# Stream output to stdout -> will be visible in docker container stdout in local mode and in cloud watch when using dedicated endpoints.\u001b[39;49;00m\r\n",
      "logging.basicConfig(stream=sys.stdout, format=\u001b[33m\"\u001b[39;49;00m\u001b[33m%(message)s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, level=logging.INFO)\r\n",
      "\r\n",
      "\u001b[37m## NOTE:\u001b[39;49;00m\r\n",
      "\u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33mThe methods input_fn and output_fn are OPTIONAL.\u001b[39;49;00m\r\n",
      "\u001b[33mIf obmitted SageMaker will assume:\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33mthe input and output objects are of type NPY format with Content-Type application/x-npy.\u001b[39;49;00m\r\n",
      "\u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\r\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m    A function to load up your model into memory.\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    The return of this function is passed to predict_fn at the time of inference.\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    This function is only run once at the start if the container/endpoint.\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    Returns:\u001b[39;49;00m\r\n",
      "\u001b[33m      - model object. Return value of this function is passed to predict_fn\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[37m# Boilerplate code - you dont need to worry about model_dir\u001b[39;49;00m\r\n",
      "    \u001b[37m# Ensure that your model filename matches what you placed in the tar.gz\u001b[39;49;00m\r\n",
      "    \u001b[34mtry\u001b[39;49;00m:\r\n",
      "        \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mflair_model.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "            model = torch.load(f)\r\n",
      "        \r\n",
      "        logging.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mModel loaded into memory\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "        \r\n",
      "        \u001b[34mreturn\u001b[39;49;00m model\r\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\r\n",
      "        logging.exception(\u001b[33m\"\u001b[39;49;00m\u001b[33mModel could not be loaded\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "\r\n",
      "\r\n",
      "\u001b[37m# Deserialize the Invoke request body into an object we can perform prediction on\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(request_body, content_type=JSON_CONTENT_TYPE):\r\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m    This method is called by SageMaker for every inference request. It handles the INPUT DATA sent to the model/endpoint.\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    This method needs to deserialze the invoke request body into an object we can perform prediction on.\u001b[39;49;00m\r\n",
      "\u001b[33m    \u001b[39;49;00m\r\n",
      "\u001b[33m    It currently natively supports serialized form \"application/json\" format only. \u001b[39;49;00m\r\n",
      "\u001b[33m   \u001b[39;49;00m\r\n",
      "\u001b[33m    However, this can be easily extended as show below (i.e. text/csv)\u001b[39;49;00m\r\n",
      "\u001b[33m    \u001b[39;49;00m\r\n",
      "\u001b[33m    Returns:\u001b[39;49;00m\r\n",
      "\u001b[33m      - formatted data used for prediction. The return value of this function is passed to predict_fn\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \r\n",
      "    \u001b[37m# If the request is submitted/serialized as application/json\u001b[39;49;00m\r\n",
      "    \u001b[34mif\u001b[39;49;00m content_type.lower() == JSON_CONTENT_TYPE:\r\n",
      "        inference_text = json.loads(request_body)\r\n",
      "    \r\n",
      "    \u001b[37m# If the request is submitted/serialized as text/csv\u001b[39;49;00m\r\n",
      "    \u001b[34melif\u001b[39;49;00m content_type.lower() == CSV_CONTENT_TYPE:\r\n",
      "        inference_text=request_body\r\n",
      "    \r\n",
      "    \u001b[34melse\u001b[39;49;00m:\r\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(f\u001b[33m\"\u001b[39;49;00m\u001b[33mFormat {content_type} is not supported. Please use one of {[JSON_CONTENT_TYPE, CSV_CONTENT_TYPE]}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[37m# Turning the request_body into a FLAIR sentence\u001b[39;49;00m\r\n",
      "    \u001b[34mtry\u001b[39;49;00m:\r\n",
      "        input_object = Sentence(inference_text)\r\n",
      "        \r\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\r\n",
      "        logging.exception(\u001b[33m\"\u001b[39;49;00m\u001b[33mConverting inference text to FLAIR sentence failed.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    logging.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mInput serialization succesfully completed.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[34mreturn\u001b[39;49;00m input_object\r\n",
      "\r\n",
      "\r\n",
      "\u001b[37m# Perform prediction on the deserialized object, with the loaded model\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_object, model):\r\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m    This function is called by SageMaker for every inference request.\u001b[39;49;00m\r\n",
      "\u001b[33m    \u001b[39;49;00m\r\n",
      "\u001b[33m    This method takes the deserialized request object and performs inference against the loaded model.\u001b[39;49;00m\r\n",
      "\u001b[33m    \u001b[39;49;00m\r\n",
      "\u001b[33m    Returns:\u001b[39;49;00m\r\n",
      "\u001b[33m      - predictions in framework specific format.\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[37m# defaults to cuda:0\u001b[39;49;00m\r\n",
      "    device = torch.device(\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[34mtry\u001b[39;49;00m:\r\n",
      "        model.to(device) \u001b[37m# ensuring your model is loaded on the approriate hardware\u001b[39;49;00m\r\n",
      "\r\n",
      "        model.eval() \u001b[37m# model.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.\u001b[39;49;00m\r\n",
      "\r\n",
      "        \u001b[34mwith\u001b[39;49;00m torch.no_grad(): \u001b[37m# torch.no_grad() impacts the autograd engine and deactivates it. It will reduce memory usage and speed up computations\u001b[39;49;00m\r\n",
      "\r\n",
      "            prediction = model.predict(input_object)\r\n",
      "\r\n",
      "        logging.info(f\u001b[33m\"\u001b[39;49;00m\u001b[33mModel prediction: {str(prediction)}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "        \r\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\r\n",
      "        logging.exception(\u001b[33m\"\u001b[39;49;00m\u001b[33mInference failed.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[34mreturn\u001b[39;49;00m prediction\r\n",
      "\r\n",
      "\u001b[37m# Serialize the prediction result into the desired response content type\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(prediction, accept=PICKLE_CONTENT_TYPE):\r\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    This function is called by SageMaker for every inference request to serialize predictions in desired format for end-user consumption.\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    This method takes the result of prediction and serializes this according to the response content type (accept).\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    For our purposes, we will pickle the response of type flair.data.Sentence\u001b[39;49;00m\r\n",
      "\u001b[33m    \u001b[39;49;00m\r\n",
      "\u001b[33m    Returns:\u001b[39;49;00m\r\n",
      "\u001b[33m      - serialized prediction object to send back to client.\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \r\n",
      "    \u001b[34mif\u001b[39;49;00m accept.lower() == PICKLE_CONTENT_TYPE:\r\n",
      "        \u001b[34mtry\u001b[39;49;00m:\r\n",
      "            output = pickle.dumps(prediction)\r\n",
      "        \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\r\n",
      "            logging.exception(\u001b[33m\"\u001b[39;49;00m\u001b[33mPickling of FLAIR sentence object failed.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[34melif\u001b[39;49;00m accept.lower() == CSV_CONTENT_TYPE:\r\n",
      "        output = \u001b[36mstr\u001b[39;49;00m(prediction)\r\n",
      "\r\n",
      "    \u001b[37m# Note how you can add additional logic here - i.e. json.dumps({result: str(prediction)})\u001b[39;49;00m\r\n",
      "    \u001b[34melif\u001b[39;49;00m accept.lower() == JSON_CONTENT_TYPE:\r\n",
      "        output = json.dumps(\u001b[36mstr\u001b[39;49;00m(prediction))            \r\n",
      "    \r\n",
      "    \u001b[34melse\u001b[39;49;00m:\r\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(f\u001b[33m\"\u001b[39;49;00m\u001b[33mFormat {accept} is not supported. Please use on of {[JSON_CONTENT_TYPE, CSV_CONTENT_TYPE, PICKLE_CONTENT_TYPE]}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    logging.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mOutput serilaization sucessfully completed. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[37m# returning the serilaization value to client.\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m output\r\n"
     ]
    }
   ],
   "source": [
    "# This is the inference script we will provide our predictor - take a moment to read through it.\n",
    "!pygmentize -l python source_dir/inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get some Realtime predictions from our local container using SageMaker SDK\n",
    "\n",
    "Recall, the default behaviour fo the predictor is accept (de)serializations in NPY format. We will have to alter this for our use case.\n",
    "\n",
    "This will not be required when using the boto3 invoke_endpoint API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_serializer, RealTimePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to use local session here\n",
    "local_sess = sagemaker.LocalSession()\n",
    "\n",
    "# We are going to serialize the inputs as JSON (recall default is NPY)\n",
    "# We do not need to perform any deserialization of the results as we will be returning the object as a pickle\n",
    "# execute the logic for 'application/json' in the input function\n",
    "# execute the logic for 'pickle' in the output function\n",
    "\n",
    "class FLAIRPredictor(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super().__init__(endpoint_name, sagemaker_session=local_sess, serializer=json_serializer, \n",
    "                         deserializer=None, content_type='application/json', accept='pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_data = where is the model artifact? Can also point to model on disk\n",
    "# Role = AWS IAM role associated with the notebook - permissions\n",
    "# Entrypoint = this is the inferencing script used to serve and recieve requests - we will show this\n",
    "#framework version = what version of pytorch would you like to use\n",
    "#Source dir = the folder or absolute/relative path containing the inference scripts AND any requirements.txt for the container\n",
    "pytorch_model = PyTorchModel(model_data='s3://pytorch-flair-test/model.tar.gz',\n",
    "                             role=role,\n",
    "                             entry_point='inference.py',\n",
    "                             framework_version='1.4.0',\n",
    "                             source_dir='source_dir',\n",
    "                             predictor_cls=FLAIRPredictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmpubwo1hvh_algo-1-lr1d3_1\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting flair\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading flair-0.5-py3-none-any.whl (334 kB)\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25l\r",
      "\u001b[K     |█                               | 10 kB 18.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 20 kB 18.8 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 30 kB 20.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 40 kB 23.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 51 kB 25.0 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 61 kB 26.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 71 kB 22.5 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 81 kB 23.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 92 kB 21.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 102 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 112 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 122 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 133 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 143 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 153 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 163 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 174 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 184 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 194 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 204 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 215 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 225 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 235 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 245 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 256 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 266 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 276 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 286 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 296 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 307 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 317 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 327 kB 22.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 334 kB 22.2 MB/s \r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hRequirement already satisfied: torch>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from flair->-r /opt/ml/model/code/requirements.txt (line 1)) (1.4.0)\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting hyperopt>=0.1.1\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading hyperopt-0.2.4-py2.py3-none-any.whl (964 kB)\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25l\r",
      "\u001b[K     |▍                               | 10 kB 23.5 MB/s eta 0:00:01\r",
      "\u001b[K     |▊                               | 20 kB 28.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 30 kB 32.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█▍                              | 40 kB 33.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 51 kB 33.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 61 kB 36.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 71 kB 36.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 81 kB 38.5 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 92 kB 39.7 MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 102 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 112 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 122 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 133 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 143 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 153 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 163 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 174 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 184 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 194 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 204 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 215 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 225 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 235 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 245 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 256 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 266 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 276 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 286 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 296 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 307 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 317 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 327 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 337 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 348 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 358 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 368 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 378 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 389 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 399 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 409 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 419 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 430 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 440 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 450 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 460 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 471 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 481 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 491 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 501 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 512 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 522 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 532 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 542 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 552 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 563 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 573 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 583 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 593 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 604 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 614 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 624 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 634 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 645 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 655 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 665 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 675 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 686 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 696 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 706 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 716 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 727 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 737 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 747 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 757 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 768 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 778 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 788 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 798 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 808 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 819 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 829 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 839 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 849 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 860 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 870 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 880 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 890 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 901 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 911 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 921 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 931 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 942 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 952 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 962 kB 38.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 964 kB 38.9 MB/s \r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hCollecting regex\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading regex-2020.5.14-cp36-cp36m-manylinux2010_x86_64.whl (675 kB)\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25l\r",
      "\u001b[K     |▌                               | 10 kB 34.5 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 20 kB 26.0 MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 30 kB 31.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 40 kB 35.0 MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 51 kB 36.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 61 kB 38.7 MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 71 kB 40.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 81 kB 42.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 92 kB 43.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 102 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 112 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 122 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 133 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 143 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 153 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 163 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 174 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 184 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 194 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 204 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 215 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 225 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 235 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 245 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 256 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 266 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 276 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 286 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 296 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 307 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 317 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 327 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 337 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 348 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 358 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 368 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 378 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 389 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 399 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 409 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 419 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 430 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 440 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 450 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 460 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 471 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 481 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 491 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 501 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 512 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 522 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 532 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 542 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 552 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 563 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 573 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 583 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 593 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 604 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 614 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 624 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 634 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 645 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 655 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 665 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 675 kB 44.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 675 kB 44.3 MB/s \r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hCollecting tabulate\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting mpld3==0.3\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading mpld3-0.3.tar.gz (788 kB)\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25l\r",
      "\u001b[K     |▍                               | 10 kB 3.5 MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 20 kB 6.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 30 kB 8.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 40 kB 10.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 51 kB 12.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 61 kB 13.7 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 71 kB 15.0 MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 81 kB 16.4 MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 92 kB 17.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 102 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 112 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 122 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 133 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 143 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 153 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 163 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 174 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 184 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 194 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 204 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 215 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 225 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 235 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 245 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 256 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 266 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 276 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 286 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 296 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 307 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 317 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 327 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 337 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 348 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 358 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 368 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 378 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 389 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 399 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 409 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 419 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 430 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 440 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 450 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 460 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 471 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 481 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 491 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 501 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 512 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 522 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 532 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 542 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 552 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 563 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 573 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 583 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 593 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 604 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 614 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 624 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 634 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 645 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 655 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 665 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 675 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 686 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 696 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 706 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 716 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 727 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 737 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 747 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 757 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 768 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 778 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 788 kB 18.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 788 kB 18.3 MB/s \r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hCollecting deprecated>=1.2.4\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading Deprecated-1.2.10-py2.py3-none-any.whl (8.7 kB)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting bpemb>=0.2.9\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading bpemb-0.3.0-py3-none-any.whl (19 kB)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from flair->-r /opt/ml/model/code/requirements.txt (line 1)) (2.8.1)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting pytest>=5.3.2\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading pytest-5.4.3-py3-none-any.whl (248 kB)\n",
      "\u001b[K     |████████████████████████████████| 248 kB 47.2 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hCollecting matplotlib>=2.2.3\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading matplotlib-3.2.1-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 36.0 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hCollecting sqlitedict>=1.6.0\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading sqlitedict-1.6.0.tar.gz (29 kB)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting transformers>=2.10.0\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading transformers-2.11.0-py3-none-any.whl (674 kB)\n",
      "\u001b[K     |████████████████████████████████| 674 kB 36.5 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hCollecting scikit-learn>=0.21.3\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 38.0 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hCollecting langdetect\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading langdetect-1.0.8.tar.gz (981 kB)\n",
      "\u001b[K     |████████████████████████████████| 981 kB 38.9 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hCollecting gensim>=3.4.0\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 34.5 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /opt/conda/lib/python3.6/site-packages (from flair->-r /opt/ml/model/code/requirements.txt (line 1)) (4.44.1)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting segtok>=1.5.7\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading segtok-1.5.10.tar.gz (25 kB)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (1.3.0)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (0.18.2)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (1.12.0)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting networkx>=2.2\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading networkx-2.4-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 41.5 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (1.16.4)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting cloudpickle\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading cloudpickle-1.4.1-py3-none-any.whl (26 kB)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting wrapt<2,>=1.10\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from bpemb>=0.2.9->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (2.22.0)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting sentencepiece\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 39.4 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hCollecting more-itertools>=4.0.0\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading more_itertools-8.3.0-py3-none-any.whl (44 kB)\n",
      "\u001b[K     |████████████████████████████████| 44 kB 4.8 MB/s  eta 0:00:01\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hRequirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from pytest>=5.3.2->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (0.1.9)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting packaging\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading packaging-20.4-py2.py3-none-any.whl (37 kB)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting importlib-metadata>=0.12; python_version < \"3.8\"\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading importlib_metadata-1.6.0-py2.py3-none-any.whl (30 kB)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting pluggy<1.0,>=0.12\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting attrs>=17.4.0\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting py>=1.5.0\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading py-1.8.1-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 2.9 MB/s  eta 0:00:01\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 6.8 MB/s  eta 0:00:01\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hCollecting cycler>=0.10\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting kiwisolver>=1.0.1\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading kiwisolver-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 9.0 MB/s  eta 0:00:01\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hCollecting tokenizers==0.7.0\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 47.9 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hCollecting dataclasses; python_version < \"3.7\"\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading dataclasses-0.7-py3-none-any.whl (18 kB)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting filelock\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting sacremoses\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 41.9 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (0.14.1)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting smart-open>=1.8.1\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading smart_open-2.0.0.tar.gz (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 47.1 MB/s eta 0:00:01\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.2->hyperopt>=0.1.1->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (4.4.2)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->bpemb>=0.2.9->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (1.25.8)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->bpemb>=0.2.9->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (2.8)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->bpemb>=0.2.9->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (2019.11.28)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->bpemb>=0.2.9->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (3.0.4)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting zipp>=0.5\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers>=2.10.0->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (7.1.1)\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Collecting boto\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25l\r",
      "\u001b[K     |▎                               | 10 kB 27.3 MB/s eta 0:00:01\r",
      "\u001b[K     |▌                               | 20 kB 18.1 MB/s eta 0:00:01\r",
      "\u001b[K     |▊                               | 30 kB 23.0 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 40 kB 21.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 51 kB 22.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 61 kB 24.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 71 kB 25.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 81 kB 26.7 MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 92 kB 27.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 102 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 112 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 122 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 133 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 143 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 153 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 163 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 174 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 184 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 194 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 204 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 215 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 225 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 235 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 245 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 256 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 266 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 276 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 286 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 296 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 307 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 317 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 327 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 337 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 348 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 358 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 368 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 378 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 389 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 399 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 409 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 419 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 430 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 440 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 450 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 460 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 471 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 481 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 491 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 501 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 512 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 522 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 532 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 542 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 552 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 563 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 573 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 583 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 593 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 604 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 614 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 624 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 634 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 645 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 655 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 665 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 675 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 686 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 696 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 706 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 716 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 727 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 737 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 747 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 757 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 768 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 778 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 788 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 798 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 808 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 819 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 829 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 839 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 849 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 860 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 870 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 880 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 890 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 901 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 911 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 921 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 931 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 942 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 952 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 962 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 972 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 983 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 993 kB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 1.0 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 1.0 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 1.0 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 1.0 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 1.0 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 1.1 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 1.1 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 1.1 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 1.1 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 1.1 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 1.1 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 1.1 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 1.1 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 1.1 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.1 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 1.2 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 1.2 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 1.2 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 1.2 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 1.2 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 1.2 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 1.2 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.2 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 1.2 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 1.2 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 1.3 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.3 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 1.3 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 1.3 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 1.3 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 1.3 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.3 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 1.3 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 1.3 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 1.4 MB 28.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.4 MB 28.9 MB/s \r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25hRequirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim>=3.4.0->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (1.12.35)\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.4.0->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (0.9.5)\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.4.0->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (0.3.3)\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Requirement already satisfied: botocore<1.16.0,>=1.15.35 in /opt/conda/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim>=3.4.0->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (1.15.35)\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.16.0,>=1.15.35->boto3->smart-open>=1.8.1->gensim>=3.4.0->flair->-r /opt/ml/model/code/requirements.txt (line 1)) (0.15.2)\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Building wheels for collected packages: mpld3, sqlitedict, langdetect, segtok, wrapt, sacremoses, smart-open\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Building wheel for mpld3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25h  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116678 sha256=ce738d41b1b7a14d20b516f9707d5d4258739a5f8131ac2c8c73fdbf3e41ba21\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/c0/74/c9/ac92f0c4c9eb137d440e86c2822aba0b96b63e608dd5737164\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-py3-none-any.whl size=14688 sha256=4b9f0c7eeb7da61b08a8b832a0991463893b5d15937b03345a3878cee196b608\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/7d/44/14/5dc41bad7fa0e87462127d2beba1eaae0c180c98f1024a31db\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.8-py3-none-any.whl size=993191 sha256=df918ea93375b74e5d56a1d12e01f8a6953bdff226192a41139991043a0ad47d\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/53/88/5d/b239dc55d773b01fdd2059606b1a8f4b64548848b8f6e381c3\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Building wheel for segtok (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25h  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25019 sha256=9e6930c1548dc2b311e3c7e789bc6ab4ac0045569e380fb16578453703ef39f4\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/1d/83/ac/c2a4c7b2b759f73532a789561b025d9887bf641bdd676f77bb\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=66132 sha256=e19c5b0a41979b192a9316af99e4358431a1ce7e2fdc3b49739a8b976c1a68a6\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=1493f94b0d996f8bdf1260562e1cb30336000b96f9dcb9d83b89124facc5eec1\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m \u001b[?25h  Created wheel for smart-open: filename=smart_open-2.0.0-py3-none-any.whl size=101341 sha256=fd4b0c09f61857987bacb09029e8f03fcacd85d8756331324ca07eae2f8aea38\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/16/64/85/f3205b74e01a98fb81e081c0d61c2ecd04e4645a986db3726e\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Successfully built mpld3 sqlitedict langdetect segtok wrapt sacremoses smart-open\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Installing collected packages: networkx, cloudpickle, hyperopt, regex, tabulate, mpld3, wrapt, deprecated, boto, smart-open, gensim, sentencepiece, bpemb, more-itertools, pyparsing, packaging, zipp, importlib-metadata, pluggy, attrs, py, pytest, cycler, kiwisolver, matplotlib, sqlitedict, tokenizers, dataclasses, filelock, sacremoses, transformers, threadpoolctl, scikit-learn, langdetect, segtok, flair\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m   Attempting uninstall: scikit-learn\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m     Found existing installation: scikit-learn 0.21.2\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m     Uninstalling scikit-learn-0.21.2:\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m       Successfully uninstalled scikit-learn-0.21.2\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Successfully installed attrs-19.3.0 boto-2.49.0 bpemb-0.3.0 cloudpickle-1.4.1 cycler-0.10.0 dataclasses-0.7 deprecated-1.2.10 filelock-3.0.12 flair-0.5 gensim-3.8.3 hyperopt-0.2.4 importlib-metadata-1.6.0 kiwisolver-1.2.0 langdetect-1.0.8 matplotlib-3.2.1 more-itertools-8.3.0 mpld3-0.3 networkx-2.4 packaging-20.4 pluggy-0.13.1 py-1.8.1 pyparsing-2.4.7 pytest-5.4.3 regex-2020.5.14 sacremoses-0.0.43 scikit-learn-0.23.1 segtok-1.5.10 sentencepiece-0.1.91 smart-open-2.0.0 sqlitedict-1.6.0 tabulate-0.8.7 threadpoolctl-2.1.0 tokenizers-0.7.0 transformers-2.11.0 wrapt-1.12.1 zipp-3.1.0\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:21,364 [INFO ] main com.amazonaws.ml.mms.ModelServer - \n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m MMS Home: /opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Current directory: /\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Temp directory: /home/model-server/tmp\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Number of GPUs: 1\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Number of CPUs: 4\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Max heap size: 13646 M\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Python executable: /opt/conda/bin/python\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Config file: /etc/sagemaker-mms.properties\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Inference address: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Management address: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Model Store: /.sagemaker/mms/models\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Initial Models: ALL\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Log dir: /logs\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Metrics dir: /logs\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Netty threads: 0\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Netty client threads: 0\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Default workers per model: 1\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Blacklist Regex: N/A\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Maximum Response Size: 6553500\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Maximum Request Size: 6553500\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:21,437 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:21,456 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:21,576 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m Model server started.\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:21,580 [WARN ] pool-2-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:21,612 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:21,612 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]85\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:21,613 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:21,613 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.6\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:21,619 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:21,632 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:22,651 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - PyTorch version 1.4.0 available.\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:24,131 [INFO ] pool-1-thread-2 ACCESS_LOG - /172.18.0.1:36168 \"GET /ping HTTP/1.1\" 200 14\n",
      "!\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:27,410 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model loaded into memory\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:27,412 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 5754\n"
     ]
    }
   ],
   "source": [
    "# initial_instance_count = 1 (1 container locally in this case)\n",
    "# instance type = 'local_gpu' - we want to use the attached gpu and not the CPU\n",
    "pytorch_model_local = pytorch_model.deploy(initial_instance_count=1, instance_type='local_gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York City (NYC), often called The City or simply New York (NY), is the most populous city in the United States.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_to_predict  = \"New York City (NYC), often called The City or simply New York (NY), is the most populous city in the United States.\"\n",
    "sentence_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:43,120 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Input serialization succesfully completed.\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:43,457 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model prediction: [Sentence: \"New York City (NYC), often called The City or simply New York (NY), is the most populous city in the United States.\"   [− Tokens: 22  − Token-Labels: \"New <B-LOC> York <I-LOC> City <E-LOC> (NYC), often called The <B-LOC> City <E-LOC> or simply New <B-LOC> York <E-LOC> (NY), is the most populous city in the United <B-LOC> States. <E-LOC>\"]]\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:43,458 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Output serilaization sucessfully completed. \n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:43,459 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 340\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:43,460 [INFO ] W-9000-model ACCESS_LOG - /172.18.0.1:36172 \"POST /invocations HTTP/1.1\" 200 344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Sentence: \"New York City (NYC), often called The City or simply New York (NY), is the most populous city in the United States.\"   [− Tokens: 22  − Token-Labels: \"New <B-LOC> York <I-LOC> City <E-LOC> (NYC), often called The <B-LOC> City <E-LOC> or simply New <B-LOC> York <E-LOC> (NY), is the most populous city in the United <B-LOC> States. <E-LOC>\"]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking our string -> serializing it as a JSON payload -> loaded as a string in input_function -> returns pickle object\n",
    "pickle.loads(pytorch_model_local.predict(sentence_to_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_deserializer, csv_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get our output as 'application/json'\n",
    "pytorch_model_local.accept = 'application/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets deserialize the response (i.e. json.loads() automatically as the output_fn serialized the response into JSON (look at inference.py!))\n",
    "pytorch_model_local.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:52,555 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Input serialization succesfully completed.\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:52,706 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model prediction: [Sentence: \"New York City (NYC), often called The City or simply New York (NY), is the most populous city in the United States.\"   [− Tokens: 22  − Token-Labels: \"New <B-LOC> York <I-LOC> City <E-LOC> (NYC), often called The <B-LOC> City <E-LOC> or simply New <B-LOC> York <E-LOC> (NY), is the most populous city in the United <B-LOC> States. <E-LOC>\"]]\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:52,706 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 152\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[Sentence: \"New York City (NYC), often called The City or simply New York (NY), is the most populous city in the United States.\"   [− Tokens: 22  − Token-Labels: \"New <B-LOC> York <I-LOC> City <E-LOC> (NYC), often called The <B-LOC> City <E-LOC> or simply New <B-LOC> York <E-LOC> (NY), is the most populous city in the United <B-LOC> States. <E-LOC>\"]]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:52,706 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Output serilaization sucessfully completed. \r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:52,706 [INFO ] W-9000-model ACCESS_LOG - /172.18.0.1:36172 \"POST /invocations HTTP/1.1\" 200 153\r\n"
     ]
    }
   ],
   "source": [
    "pytorch_model_local.predict(sentence_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get our output as 'text/csv'\n",
    "pytorch_model_local.accept = 'text/csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is nothing to deserialize in the response - as its already raw text.\n",
    "pytorch_model_local.deserializer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:57,515 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Input serialization succesfully completed.\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:57,657 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model prediction: [Sentence: \"New York City (NYC), often called The City or simply New York (NY), is the most populous city in the United States.\"   [− Tokens: 22  − Token-Labels: \"New <B-LOC> York <I-LOC> City <E-LOC> (NYC), often called The <B-LOC> City <E-LOC> or simply New <B-LOC> York <E-LOC> (NY), is the most populous city in the United <B-LOC> States. <E-LOC>\"]]\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:57,658 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Output serilaization sucessfully completed. \r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[Sentence: \"New York City (NYC), often called The City or simply New York (NY), is the most populous city in the United States.\"   [− Tokens: 22  − Token-Labels: \"New <B-LOC> York <I-LOC> City <E-LOC> (NYC), often called The <B-LOC> City <E-LOC> or simply New <B-LOC> York <E-LOC> (NY), is the most populous city in the United <B-LOC> States. <E-LOC>\"]]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:57,658 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 144\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:57,658 [INFO ] W-9000-model ACCESS_LOG - /172.18.0.1:36172 \"POST /invocations HTTP/1.1\" 200 145\r\n"
     ]
    }
   ],
   "source": [
    "# comes back as a byte stream of text - so we decode. Notice how this equivalent to the above!\n",
    "pytorch_model_local.predict(sentence_to_predict).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we deserialized as csv/text?\n",
    "pytorch_model_local.deserializer = csv_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:59,395 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Input serialization succesfully completed.\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:59,525 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model prediction: [Sentence: \"New York City (NYC), often called The City or simply New York (NY), is the most populous city in the United States.\"   [− Tokens: 22  − Token-Labels: \"New <B-LOC> York <I-LOC> City <E-LOC> (NYC), often called The <B-LOC> City <E-LOC> or simply New <B-LOC> York <E-LOC> (NY), is the most populous city in the United <B-LOC> States. <E-LOC>\"]]\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:59,525 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Output serilaization sucessfully completed. \r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['[Sentence: \"New York City (NYC)',\n",
       "  ' often called The City or simply New York (NY)',\n",
       "  ' is the most populous city in the United States.\"   [− Tokens: 22  − Token-Labels: \"New <B-LOC> York <I-LOC> City <E-LOC> (NYC)',\n",
       "  ' often called The <B-LOC> City <E-LOC> or simply New <B-LOC> York <E-LOC> (NY)',\n",
       "  ' is the most populous city in the United <B-LOC> States. <E-LOC>\"]]']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:59,525 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 130\r\n",
      "\u001b[36malgo-1-lr1d3_1  |\u001b[0m 2020-06-03 18:03:59,526 [INFO ] W-9000-model ACCESS_LOG - /172.18.0.1:36172 \"POST /invocations HTTP/1.1\" 200 132\r\n"
     ]
    }
   ],
   "source": [
    "# we get the result back as if we read the result from a CSV file in python\n",
    "pytorch_model_local.predict(sentence_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "#terminate local container - everything is working as expected!\n",
    "pytorch_model_local.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets now deploy to an actual endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not need to provide image, as it will infer the latest image associated with pytorch\n",
    "# Can also provide custom image if you like.\n",
    "\n",
    "# Note how we do NOT use localsession here\n",
    "\n",
    "remote_model = PyTorchModel(model_data='s3://pytorch-flair-test/model.tar.gz',\n",
    "                   role=role,\n",
    "                   sagemaker_session=sess,\n",
    "                   entry_point='inference.py',\n",
    "                   name='flair-sequence-tagger',\n",
    "                   framework_version='1.4.0',\n",
    "                   source_dir='source_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!"
     ]
    }
   ],
   "source": [
    "remote_predictor = remote_model.deploy(initial_instance_count=1, instance_type='ml.p2.xlarge',\n",
    "                                       endpoint_name='flair-endpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'flair.data.Sentence'>\n",
      "\n",
      "Sentence: \"New York City (NYC), often called The City or simply New York (NY), is the most populous city in the United States.\"   [− Tokens: 22  − Token-Labels: \"New <B-LOC> York <I-LOC> City <E-LOC> (NYC), often called The <B-LOC> City <E-LOC> or simply New <B-LOC> York <E-LOC> (NY), is the most populous city in the United <B-LOC> States. <E-LOC>\"]\n"
     ]
    }
   ],
   "source": [
    "# We will now use the boto3 API to obtain inferences from our endpoint\n",
    "# Note that the boto3 endpoint, simply submits the raw payload as is! No serilization or deserialization done\n",
    "# Except for logic associated in our inference.py\n",
    "\n",
    "sentence_to_predict  = \"New York City (NYC), often called The City or simply New York (NY), is the most populous city in the United States.\"\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "content_type = 'application/json'\n",
    "accept_type = \"pickle\" \n",
    "payload = json.dumps(sentence_to_predict)\n",
    "endpoint_name = \"flair-endpoint\"\n",
    "\n",
    "resp = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=payload,\n",
    "    ContentType=content_type,\n",
    "    Accept = accept_type\n",
    ")\n",
    "\n",
    "result = pickle.loads(resp['Body'].read())[0]\n",
    "print(type(result))\n",
    "print()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets take a look at batch transform!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_path = f's3://{bucket}/{prefix_input}/sample.csv'\n",
    "output_data_path = f's3://{bucket}/{prefix_output}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 385 Bytes/385 Bytes (5.2 KiB/s) with 1 file(s) remaining\r",
      "upload: ./sample.csv to s3://sagemaker-us-east-1-544194174732/flair-input/sample.csv\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp sample.csv $input_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_job = sagemaker.transformer.Transformer(\n",
    "    model_name = \"flair-sequence-tagger\",\n",
    "    instance_count = 1,\n",
    "    instance_type = 'ml.p2.xlarge',\n",
    "    strategy = 'SingleRecord',\n",
    "    assemble_with = 'Line',\n",
    "    output_path = output_data_path,\n",
    "    base_transform_job_name='flair-transform-batch-transform-1',\n",
    "    sagemaker_session=sess,\n",
    "    accept = \"text/csv\") # note how we are changing the return type\n",
    "\n",
    "transform_job.transform(data = input_data_path, \n",
    "                        content_type = \"text/csv\",# note how the input type has changed \n",
    "                        split_type = 'Line') # one record per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform job is still in status: InProgress\n",
      "Transform job is still in status: InProgress\n",
      "Transform job is still in status: InProgress\n",
      "Transform job is still in status: InProgress\n",
      "Transform job is still in status: InProgress\n",
      "Transform job is still in status: InProgress\n",
      "Transform job is still in status: InProgress\n",
      "Transform job is still in status: InProgress\n",
      "Transform job is still in status: InProgress\n",
      "Transform job is still in status: InProgress\n",
      "Transform job is still in status: InProgress\n",
      "Transform job is still in status: InProgress\n",
      "Transform job is still in status: InProgress\n",
      "Transform job is still in status: InProgress\n",
      "Transform job is still in status: InProgress\n",
      "Transform job ended with status: Completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "while(True):\n",
    "    response = sm.describe_transform_job(TransformJobName='flair-transform-batch-transform-1-2020-06-03-19-47-29-557')\n",
    "    status = response['TransformJobStatus']\n",
    "    if  status == 'Completed':\n",
    "        print(\"Transform job ended with status: \" + status)\n",
    "        break\n",
    "    if status == 'Failed':\n",
    "        message = response['FailureReason']\n",
    "        print('Transform failed with the following error: {}'.format(message))\n",
    "        raise Exception('Transform job failed') \n",
    "    print(\"Transform job is still in status: \" + status)    \n",
    "    time.sleep(30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-03 19:55:23       1036 sample.csv.out\r\n"
     ]
    }
   ],
   "source": [
    "# our output file\n",
    "! aws s3 ls $output_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1.0 KiB/1.0 KiB (19.5 KiB/s) with 1 file(s) remaining\r",
      "download: s3://sagemaker-us-east-1-544194174732/flair-ouput/sample.csv.out to ./results.csv\r\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp \"s3://sagemaker-us-east-1-544194174732/flair-ouput/sample.csv.out\" results.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence: \"New York City (NYC), often called The City or simply New York (NY), is the most populous city in the United States.\r\n",
      "\"   [− Tokens: 22  − Token-Labels: \"New <B-LOC> York <I-LOC> City <E-LOC> (NYC), often called The <B-LOC> City <E-LOC> or simply New <B-LOC> York <E-LOC> (NY), is the most populous city in the United <B-LOC> States.\r\n",
      " <E-LOC>\"]]\r\n",
      "[Sentence: \"Paris is the capital and most populous city of France, with a population of 2,148,271 residents (official estimate, 1 January 2020) in an area of 105 square kilometres (41 square miles).\r\n",
      "\"   [− Tokens: 31  − Token-Labels: \"Paris <S-LOC> is the capital and most populous city of France, <S-LOC> with a population of 2,148,271 residents (official estimate, 1 January 2020) in an area of 105 square kilometres (41 square miles).\r\n",
      "\"]]\r\n",
      "[Sentence: \"Berlin is the capital and largest city of Germany by both area and population.\r\n",
      "\"   [− Tokens: 14  − Token-Labels: \"Berlin <S-LOC> is the capital and largest city of Germany <S-LOC> by both area and population.\r\n",
      "\"]]\r\n"
     ]
    }
   ],
   "source": [
    "! cat results.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
